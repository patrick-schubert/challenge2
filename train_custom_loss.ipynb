{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cenpes/anaconda3/envs/DL/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/cenpes/anaconda3/envs/DL/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/cenpes/anaconda3/envs/DL/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/cenpes/anaconda3/envs/DL/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/cenpes/anaconda3/envs/DL/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/cenpes/anaconda3/envs/DL/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc, fbeta_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from opt import RAdam\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '8'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import efficientnet.keras as efn\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Add, BatchNormalization, Input, Dense, MaxPooling2D, Conv2D, Flatten, Concatenate\n",
    "from keras.layers.core import Activation, Layer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import keras.backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.tensorflow_backend.set_session(tf.Session(config=config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Dataset\n",
      "(89991, 200, 200, 3)\n",
      "(10000, 200, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing Dataset\")\n",
    "\n",
    "data_dir = '/home/dados4t/DataChallenge2/'\n",
    "\n",
    "images = np.load(os.path.join(data_dir,'images_efn_vis.npy'))\n",
    "is_lens = np.load(os.path.join(data_dir,'Y.npy'))\n",
    "#pad = np.zeros((images.shape[0],images.shape[1],images.shape[2],1), dtype=\"float32\")\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(images, is_lens, test_size = 0.10, random_state = 7)\n",
    "del images\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model\n"
     ]
    }
   ],
   "source": [
    "print(\"Building Model\")\n",
    "\n",
    "inp = Input((200,200,3))\n",
    "efn_arc = efn.EfficientNetB2(input_tensor = inp, weights='imagenet')\n",
    "\n",
    "y_hat = Dense(2,activation =\"sigmoid\")(efn_arc.layers[-2].output)\n",
    "\n",
    "model = Model(efn_arc.input, y_hat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 35\n",
    "def fbeta(y_true, y_pred):\n",
    "    TP = (K.sum((y_pred * y_true), axis=-1)) / batch_size\n",
    "    FP = (K.sum(((1 - y_pred) * y_true), axis=-1)) / batch_size\n",
    "    FN = (K.sum((y_pred * (1 - y_true)), axis=-1)) / batch_size\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    fbeta = (1 + 0.001) * precision * recall / ( 0.001 * precision + recall)\n",
    "    fbeta = 1 - K.mean(fbeta)\n",
    "    return fbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss = 'categorical_crossentropy', optimizer=RAdam(),metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = fbeta, optimizer=RAdam(clipnorm=0.001),metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n",
      "Epoch 1/20\n",
      " 433/2571 [====>.........................] - ETA: 53:43 - loss: 0.0414 - acc: 0.5030"
     ]
    }
   ],
   "source": [
    "print(\"Training Model\")\n",
    "\n",
    "model_name = \"efn2_vis_TEST.hdf5\"\n",
    "batch_size = 35\n",
    "check = ModelCheckpoint(model_name, monitor=\"val_loss\", verbose=1, save_best_only=True)\n",
    "\n",
    "gen = ImageDataGenerator(\n",
    "\t\trotation_range=180,\n",
    "\t\tzoom_range=0.20,\n",
    "\t\tvertical_flip = True,\n",
    "    horizontal_flip=True,\n",
    "\t\tfill_mode=\"nearest\")\n",
    "\"\"\"\n",
    "def gen_flow_for_three_inputs(X1, X2, X3, y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=1)\n",
    "    genX2 = gen.flow(X2, batch_size=batch_size,seed=1)\n",
    "    genX3 = gen.flow(X3, batch_size=batch_size,seed=1)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            X3i = genX3.next()\n",
    "            #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield [X1i[0], X2i, X3i], X1i[1]\n",
    "\n",
    "gen_flow = gen_flow_for_three_inputs(X_train_h, X_train_j, X_train_y, Y_train)\n",
    "\"\"\"\n",
    "\n",
    "history = model.fit_generator(gen.flow(X_train, Y_train, batch_size = batch_size), epochs = 20,  \n",
    "            verbose = 1, validation_data= (X_test, Y_test), callbacks=[check], \n",
    "            steps_per_epoch = X_train.shape[0] // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
